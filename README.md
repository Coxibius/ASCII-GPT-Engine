\#  ASCII-GPT: Investigaci贸n sobre Auto-Correcci贸n y Generaci贸n Estructural



> Un estudio emp铆rico sobre c贸mo entrenar LLMs peque帽os (GPT-2) para entender estructuras visuales (ASCII Art) mediante refinamiento iterativo asistido por IA.



\##  Resumen del Proyecto

Este proyecto documenta la evoluci贸n de un modelo de lenguaje entrenado para "dibujar" con caracteres. El proceso fue dirigido 100% mediante ingenier铆a de prompts y colaboraci贸n entre m煤ltiples agentes de IA para corregir errores de alucinaci贸n y c贸digo.



\*\*Tiempo de desarrollo:\*\* 48 horas.

\*\*Hardware:\*\* Google Colab (T4) -> Kaggle (T4 x2).



\## К Evoluci贸n de los Modelos

\- \*\*V1-V2:\*\* Aprendizaje de texturas (Travian Dataset). \*Fallo: Falta de geometr铆a.\*

\- \*\*V3:\*\* Expansi贸n de dataset (Scraping masivo). \*Fallo: Overfitting al espacio en blanco.\*

\- \*\*V4-V5:\*\* Ajuste fino (Hardcore Training). \*Logro: Estructura perfecta, firmas de autores replicadas.\*

\- \*\*V6 (Actual):\*\* Limpieza de datos y eliminaci贸n de sesgos (Firmas).



\##  Estructura del Repositorio

\- `/docs`: Bit谩coras diarias y contextos de iteraci贸n (Diarios de Investigaci贸n).

\- `/scripts`: Herramientas Python desarrolladas para miner铆a y limpieza de datos.

\- `/notebooks`: C贸digo de entrenamiento reproducible.



\##  Descarga de Modelos

Los modelos entrenados (.zip) est谩n disponibles en la secci贸n \[Releases](https://github.com/TU\_USUARIO/ASCII-GPT-Engine/releases).

