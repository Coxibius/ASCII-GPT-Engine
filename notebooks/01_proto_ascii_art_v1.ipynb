{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a22f60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:05:32.329576Z",
     "iopub.status.busy": "2025-12-02T15:05:32.328949Z",
     "iopub.status.idle": "2025-12-02T15:06:54.583793Z",
     "shell.execute_reply": "2025-12-02T15:06:54.582882Z",
     "shell.execute_reply.started": "2025-12-02T15:05:32.329546Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-12-03T01:27:19.836159",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- BLOQUE 1: INSTALACI√ìN ---\n",
    "print(\"‚è≥ Instalando librer√≠as...\")\n",
    "!pip install -U transformers datasets accelerate\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    DataCollatorForLanguageModeling, \n",
    "    GPT2LMHeadModel, \n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# Verificamos GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU Detectada: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ¬°OJO! No detecto GPU. Revisa los 'Session Options' a la derecha.\")\n",
    "\n",
    "print(\"‚úÖ BLOQUE 1 TERMINADO: Librer√≠as instaladas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e6433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:09:06.226585Z",
     "iopub.status.busy": "2025-12-02T15:09:06.225906Z",
     "iopub.status.idle": "2025-12-02T15:09:06.629177Z",
     "shell.execute_reply": "2025-12-02T15:09:06.628602Z",
     "shell.execute_reply.started": "2025-12-02T15:09:06.226556Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- BLOQUE 2: CARGAR DATOS ---\n",
    "# Ruta exacta basada en tu captura\n",
    "dataset_file = \"/kaggle/input/dataset-clean-v2/dataset_TRAVIAN_CLEAN_V2.txt\"\n",
    "\n",
    "if os.path.exists(dataset_file):\n",
    "    print(f\"‚úÖ Archivo encontrado en: {dataset_file}\")\n",
    "    \n",
    "    # Cargamos el dataset crudo\n",
    "    dataset = load_dataset(\"text\", data_files=dataset_file)\n",
    "    dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "    print(\"‚úÖ BLOQUE 2 TERMINADO: Dataset cargado en memoria.\")\n",
    "else:\n",
    "    print(f\"‚ùå ERROR: No encuentro el archivo en {dataset_file}\")\n",
    "    print(\"Por favor, copia la ruta usando el panel derecho (Copy file path).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622d27c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:52:20.713565Z",
     "iopub.status.busy": "2025-12-02T15:52:20.712773Z",
     "iopub.status.idle": "2025-12-02T15:52:25.390522Z",
     "shell.execute_reply": "2025-12-02T15:52:25.389764Z",
     "shell.execute_reply.started": "2025-12-02T15:52:20.713535Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- BLOQUE 3: TOKENIZACI√ìN ---\n",
    "print(\"‚è≥ Iniciando tokenizaci√≥n (esto puede tardar unos minutos)...\")\n",
    "\n",
    "model_name = \"openai-community/gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def preprocess(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=1024, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "# Aqu√≠ ocurre la magia lenta\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "print(f\"üìä Datos de entrenamiento: {len(tokenized_dataset['train'])} ejemplos\")\n",
    "print(f\"üìä Datos de prueba: {len(tokenized_dataset['test'])} ejemplos\")\n",
    "print(\"‚úÖ BLOQUE 3 TERMINADO: Datos listos para entrar al cerebro de la IA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2c2d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:10:01.565276Z",
     "iopub.status.busy": "2025-12-02T15:10:01.565004Z",
     "iopub.status.idle": "2025-12-02T15:10:04.349105Z",
     "shell.execute_reply": "2025-12-02T15:10:04.348224Z",
     "shell.execute_reply.started": "2025-12-02T15:10:01.565248Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- BLOQUE 4: CONFIGURACI√ìN DEL MODELO ---\n",
    "print(\"‚è≥ Configurando GPT-2...\")\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/travian_ascii_model\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=15,            # 15 √âpocas (Fuerza Bruta)\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    logging_steps=50,               # Reportar cada 50 pasos\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ BLOQUE 4 TERMINADO: Todo listo para despegar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8c27fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:10:16.278563Z",
     "iopub.status.busy": "2025-12-02T15:10:16.278250Z",
     "iopub.status.idle": "2025-12-02T15:14:01.933293Z",
     "shell.execute_reply": "2025-12-02T15:14:01.932288Z",
     "shell.execute_reply.started": "2025-12-02T15:10:16.278539Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- BLOQUE 5: ENTRENAMIENTO Y GUARDADO ---\n",
    "print(\"üöÄ INICIANDO ENTRENAMIENTO (15 √âPOCAS)...\")\n",
    "print(\"Si ves una barra de progreso abajo, est√° funcionando.\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"üíæ Guardando modelo final...\")\n",
    "trainer.save_model(\"/kaggle/working/modelo_final\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/modelo_final\")\n",
    "\n",
    "# Crear ZIP para descargar f√°cil\n",
    "import shutil\n",
    "shutil.make_archive(\"/kaggle/working/modelo_travian_completo\", 'zip', \"/kaggle/working/modelo_final\")\n",
    "\n",
    "print(\"‚úÖ‚úÖ‚úÖ ¬°TODO TERMINADO! ‚úÖ‚úÖ‚úÖ\")\n",
    "print(\"Ve a la secci√≥n 'Output' a la derecha, refresca y descarga 'modelo_travian_completo.zip'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffae33b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:18:02.383286Z",
     "iopub.status.busy": "2025-12-02T15:18:02.382476Z",
     "iopub.status.idle": "2025-12-02T15:18:02.427955Z",
     "shell.execute_reply": "2025-12-02T15:18:02.427139Z",
     "shell.execute_reply.started": "2025-12-02T15:18:02.383260Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# 1. Conectar Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Definir rutas\n",
    "# Ajusta el nombre si tu archivo se llama diferente\n",
    "ruta_zip_drive = \"/content/drive/My Drive/ASCII-GPT/modelo_ascii_pro.pt\" \n",
    "carpeta_destino = \"./modelo_recuperado\"\n",
    "\n",
    "# 3. Descomprimir\n",
    "print(\"üì¶ Descomprimiendo tu modelo previo...\")\n",
    "shutil.unpack_archive(ruta_zip_drive, carpeta_destino, \"zip\")\n",
    "\n",
    "# 4. Verificar que el cerebro est√° ah√≠\n",
    "archivos = os.listdir(carpeta_destino)\n",
    "print(f\"‚úÖ Archivos encontrados: {archivos}\")\n",
    "\n",
    "if \"config.json\" in archivos and (\"pytorch_model.bin\" in archivos or \"model.safetensors\" in archivos):\n",
    "    print(\"üéâ ¬°EL MODELO EST√Å SANO! Podemos re-entrenar.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Mmm... falta algo. ¬øSeguro que se guard√≥ bien?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770985a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:26:30.017421Z",
     "iopub.status.busy": "2025-12-02T15:26:30.016538Z",
     "iopub.status.idle": "2025-12-02T15:26:30.493111Z",
     "shell.execute_reply": "2025-12-02T15:26:30.492333Z",
     "shell.execute_reply.started": "2025-12-02T15:26:30.017368Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# --- CONFIGURACI√ìN DE RUTAS EN KAGGLE ---\n",
    "# 1. Busca la ruta en el panel derecho (copia el path de tu archivo subido)\n",
    "# Seguramente ser√° algo como: /kaggle/input/mi-modelo-previo/modelo_ascii_pro.pt\n",
    "# O si subiste el zip: /kaggle/input/mi-modelo-previo/modelo_ascii_pro.zip\n",
    "\n",
    "# CAMBIA ESTO POR LA RUTA QUE TE SALE A LA DERECHA:\n",
    "ruta_archivo_kaggle = \"/kaggle/input/proto-ascii-art-01/modelo_ascii_pro.pt\" \n",
    "\n",
    "carpeta_destino = \"/kaggle/working/\"\n",
    "\n",
    "print(f\"üì¶ Preparando modelo desde: {ruta_archivo_kaggle}\")\n",
    "\n",
    "# 2. Descomprimir (o copiar si ya es una carpeta)\n",
    "# Si es un ZIP:\n",
    "if ruta_archivo_kaggle.endswith(\".zip\") or ruta_archivo_kaggle.endswith(\".pt\"): \n",
    "    # A veces los .pt de colab son zips disfrazados, probamos descomprimir\n",
    "    try:\n",
    "        shutil.unpack_archive(ruta_archivo_kaggle, carpeta_destino, \"zip\")\n",
    "        print(\"‚úÖ Descomprimido correctamente.\")\n",
    "    except:\n",
    "        # Si falla, quiz√°s no es zip, intentamos copiarlo tal cual\n",
    "        if not os.path.exists(carpeta_destino):\n",
    "            os.makedirs(carpeta_destino)\n",
    "        shutil.copy(ruta_archivo_kaggle, carpeta_destino)\n",
    "        print(\"‚ö†Ô∏è No era un ZIP, copiando archivo crudo...\")\n",
    "\n",
    "# 3. Verificar qu√© tenemos\n",
    "print(f\"üìÇ Contenido de la carpeta destino:\")\n",
    "print(os.listdir(carpeta_destino))\n",
    "\n",
    "# VERIFICACI√ìN VISUAL\n",
    "if os.path.exists(f\"{carpeta_destino}/config.json\"):\n",
    "    print(\"üéâ ¬°TODO LISTO! El modelo est√° cargado y listo para re-entrenar.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è OJO: No veo el config.json. Revisa si se cre√≥ una subcarpeta dentro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5c820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:28:48.516658Z",
     "iopub.status.busy": "2025-12-02T15:28:48.515943Z",
     "iopub.status.idle": "2025-12-02T15:28:48.540696Z",
     "shell.execute_reply": "2025-12-02T15:28:48.539712Z",
     "shell.execute_reply.started": "2025-12-02T15:28:48.516635Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import GPT2LMHeadModel, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "# --- 1. DETECTIVE DE CARPETAS üïµÔ∏è‚Äç‚ôÇÔ∏è ---\n",
    "# Buscamos d√≥nde cay√≥ el config.json\n",
    "base_path = \"/kaggle/working/modelo_recuperado\"\n",
    "subfolder_path = os.path.join(base_path, \"modelo_ascii_pro\")\n",
    "\n",
    "if os.path.exists(os.path.join(subfolder_path, \"config.json\")):\n",
    "    ruta_real = subfolder_path\n",
    "    print(f\"‚úÖ ¬°Encontrado! El modelo est√° en la subcarpeta: {ruta_real}\")\n",
    "elif os.path.exists(os.path.join(base_path, \"config.json\")):\n",
    "    ruta_real = base_path\n",
    "    print(f\"‚úÖ ¬°Encontrado! El modelo est√° en la ra√≠z: {ruta_real}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"‚ùå Sigo sin encontrar el config.json. Revisa la descompresi√≥n.\")\n",
    "\n",
    "# --- 2. CARGAR EL MODELO PREVIO ---\n",
    "print(\"üîÑ Cargando tu modelo anterior (Transfer Learning)...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(ruta_real)\n",
    "model = GPT2LMHeadModel.from_pretrained(ruta_real)\n",
    "\n",
    "# Asegurar tokens especiales\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Preparar el collator (necesario para el entrenador)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# --- 3. CONFIGURAR EL ENTRENAMIENTO (FASE 2) ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/travian_ascii_reloaded\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,             # 5 √âpocas extra para perfeccionar\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=3e-5,             # Un poco m√°s bajo para afinar detalles\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=200,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# --- 4. ¬°A ENTRENAR! ---\n",
    "print(\"üöÄ Iniciando Fase 2: Perfeccionamiento Geom√©trico...\")\n",
    "trainer.train()\n",
    "\n",
    "# --- 5. GUARDAR RESULTADO FINAL ---\n",
    "output_final = \"/kaggle/working/modelo_travian_v2\"\n",
    "trainer.save_model(output_final)\n",
    "tokenizer.save_pretrained(output_final)\n",
    "\n",
    "# Crear ZIP para descargar\n",
    "import shutil\n",
    "shutil.make_archive(\"/kaggle/working/modelo_travian_v2_completo\", 'zip', output_final)\n",
    "\n",
    "print(\"‚úÖ‚úÖ‚úÖ ¬°ENTRENAMIENTO COMPLETADO! ‚úÖ‚úÖ‚úÖ\")\n",
    "print(\"Descarga 'modelo_travian_v2_completo.zip' del panel derecho.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fef83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:31:40.318109Z",
     "iopub.status.busy": "2025-12-02T15:31:40.317447Z",
     "iopub.status.idle": "2025-12-02T15:31:40.346939Z",
     "shell.execute_reply": "2025-12-02T15:31:40.346096Z",
     "shell.execute_reply.started": "2025-12-02T15:31:40.318084Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import GPT2LMHeadModel, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "print(\"üïµÔ∏è‚Äç‚ôÇÔ∏è Iniciando b√∫squeda implacable del 'config.json'...\")\n",
    "\n",
    "# 1. EL SABUESO: Buscamos el archivo recursivamente\n",
    "root_dir = \"/kaggle/working\" # Buscamos en todo el espacio de trabajo\n",
    "ruta_real = None\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    # print(f\"üìÇ Revisando: {dirpath}\") # Descomenta si quieres ver por d√≥nde pasa\n",
    "    if \"config.json\" in filenames:\n",
    "        ruta_real = dirpath\n",
    "        print(f\"\\nüéâ ¬°ENCONTRADO! El modelo se esconde en: {ruta_real}\")\n",
    "        break\n",
    "\n",
    "if not ruta_real:\n",
    "    # SI LLEGAMOS AQU√ç, EL ARCHIVO NO EXISTE (EL ZIP ESTABA MAL O INCOMPLETO)\n",
    "    print(\"\\n‚ùå ERROR CR√çTICO: No encontr√© 'config.json' en ninguna parte.\")\n",
    "    print(\"Esto significa que el ZIP que subiste a Kaggle NO ten√≠a todos los archivos.\")\n",
    "    print(\"Archivos encontrados en total:\")\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for f in filenames:\n",
    "            print(os.path.join(dirpath, f))\n",
    "    raise FileNotFoundError(\"No puedo entrenar sin el config.json\")\n",
    "\n",
    "# --- SI LO ENCONTR√ì, SEGUIMOS AQU√ç ---\n",
    "\n",
    "print(\"üîÑ Cargando modelo desde la ruta encontrada...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(ruta_real)\n",
    "model = GPT2LMHeadModel.from_pretrained(ruta_real)\n",
    "\n",
    "# Asegurar tokens especiales\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# --- CONFIGURACI√ìN DE ENTRENAMIENTO (FASE 2) ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/travian_ascii_reloaded\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,             # 5 √âpocas extra\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=200,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# --- ¬°FUEGO! ---\n",
    "print(\"üöÄ Arrancando entrenamiento de una puta vez...\")\n",
    "trainer.train()\n",
    "\n",
    "# --- GUARDAR ---\n",
    "output_final = \"/kaggle/working/modelo_travian_v2\"\n",
    "trainer.save_model(output_final)\n",
    "tokenizer.save_pretrained(output_final)\n",
    "import shutil\n",
    "shutil.make_archive(\"/kaggle/working/modelo_travian_v2_completo\", 'zip', output_final)\n",
    "\n",
    "print(\"‚úÖ‚úÖ‚úÖ ¬°HECHO! ‚úÖ‚úÖ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63907dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:53:03.034065Z",
     "iopub.status.busy": "2025-12-02T15:53:03.033611Z",
     "iopub.status.idle": "2025-12-02T15:55:06.063284Z",
     "shell.execute_reply": "2025-12-02T15:55:06.062158Z",
     "shell.execute_reply.started": "2025-12-02T15:53:03.034042Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import GPT2LMHeadModel, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "# --- 1. LOCALIZADOR DEL MODELO (Basado en tu captura) ---\n",
    "print(\"üì° Escaneando ruta exacta del backup...\")\n",
    "\n",
    "# Buscamos la carpeta espec√≠fica que sale en tu foto\n",
    "nombre_carpeta_objetivo = \"Backup_Modelo_Travian_V1\"\n",
    "ruta_modelo = None\n",
    "\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    if nombre_carpeta_objetivo in dirs:\n",
    "        ruta_modelo = os.path.join(root, nombre_carpeta_objetivo)\n",
    "        print(f\"‚úÖ ¬°BLANCO FIJADO! Modelo encontrado en: {ruta_modelo}\")\n",
    "        break\n",
    "\n",
    "if not ruta_modelo:\n",
    "    # Si falla la b√∫squeda exacta, intentamos una ruta manual basada en la foto\n",
    "    ruta_modelo = \"/kaggle/input/proto-ascii-art-001/Backup_Modelo_Travian_V1\"\n",
    "    print(f\"‚ö†Ô∏è No lo encontr√© autom√°ticamente, probando ruta manual: {ruta_modelo}\")\n",
    "\n",
    "# Verificaci√≥n final de archivos clave\n",
    "if not os.path.exists(os.path.join(ruta_modelo, \"config.json\")):\n",
    "    raise FileNotFoundError(f\"‚ùå Error grave: No veo config.json en {ruta_modelo}\")\n",
    "\n",
    "# --- 2. CARGAR TU MODELO GUARDADO ---\n",
    "print(\"üîÑ Cargando pesos del modelo (esto puede tardar unos segundos)...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ruta_modelo)\n",
    "    model = GPT2LMHeadModel.from_pretrained(ruta_modelo)\n",
    "    print(\"ü§ñ Modelo cargado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error cargando el modelo: {e}\")\n",
    "    raise e\n",
    "\n",
    "# Ajustes de tokens\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Verificar que tenemos los datos procesados (del Bloque 3)\n",
    "if 'tokenized_dataset' not in globals():\n",
    "    raise NameError(\"üõë ¬°ALTO! No has corrido el BLOQUE 3 (Tokenizaci√≥n). Sube y c√≥rrelo antes de entrenar.\")\n",
    "\n",
    "# --- 3. CONFIGURAR RE-ENTRENAMIENTO (FASE 2) ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/travian_ascii_reloaded\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,              # 5 √©pocas extra sobre lo que ya sabe\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=3e-5,              # Rate bajo para refinar, no destruir\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=200,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# --- 4. ¬°A ENTRENAR! ---\n",
    "print(\"üöÄ Iniciando Re-entrenamiento (Fase 2)...\")\n",
    "trainer.train()\n",
    "\n",
    "# --- 5. GUARDAR Y EMPAQUETAR ---\n",
    "output_final = \"/kaggle/working/modelo_travian_v2_final\"\n",
    "trainer.save_model(output_final)\n",
    "tokenizer.save_pretrained(output_final)\n",
    "\n",
    "import shutil\n",
    "shutil.make_archive(\"/kaggle/working/modelo_travian_v2_completo\", 'zip', output_final)\n",
    "\n",
    "print(\"‚úÖ‚úÖ‚úÖ ¬°MISI√ìN CUMPLIDA! ‚úÖ‚úÖ‚úÖ\")\n",
    "print(\"Ve al panel derecho (Output), refresca y descarga 'modelo_travian_v2_completo.zip'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125273d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:56:11.947604Z",
     "iopub.status.busy": "2025-12-02T15:56:11.946926Z",
     "iopub.status.idle": "2025-12-02T15:56:54.189656Z",
     "shell.execute_reply": "2025-12-02T15:56:54.188570Z",
     "shell.execute_reply.started": "2025-12-02T15:56:11.947578Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# ESTO CALLA EL AVISO ROJO Y EVITA EL BLOQUEO\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from transformers import GPT2LMHeadModel, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "# --- 1. LOCALIZADOR DEL MODELO ---\n",
    "# (Esto ya funcion√≥, lo dejamos igual)\n",
    "nombre_carpeta_objetivo = \"Backup_Modelo_Travian_V1\"\n",
    "ruta_modelo = None\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    if nombre_carpeta_objetivo in dirs:\n",
    "        ruta_modelo = os.path.join(root, nombre_carpeta_objetivo)\n",
    "        break\n",
    "if not ruta_modelo:\n",
    "    ruta_modelo = \"/kaggle/input/proto-ascii-art-001/Backup_Modelo_Travian_V1\"\n",
    "\n",
    "print(f\"‚úÖ Usando modelo en: {ruta_modelo}\")\n",
    "\n",
    "# --- 2. CARGAR MODELO ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(ruta_modelo)\n",
    "model = GPT2LMHeadModel.from_pretrained(ruta_modelo)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# --- 3. CONFIGURAR RE-ENTRENAMIENTO (CORREGIDO) ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/travian_ascii_reloaded\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=200,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    # üö® AQU√ç EST√Å EL CAMBIO M√ÅGICO üö®\n",
    "    dataloader_num_workers=0  # Ponemos 0 para evitar el deadlock. ¬°Esto volar√°!\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# --- 4. ¬°A ENTRENAR R√ÅPIDO! ---\n",
    "print(\"üöÄ Iniciando Re-entrenamiento (Modo Turbo)...\")\n",
    "trainer.train()\n",
    "\n",
    "# --- 5. GUARDAR ---\n",
    "output_final = \"/kaggle/working/modelo_travian_v2_final\"\n",
    "trainer.save_model(output_final)\n",
    "tokenizer.save_pretrained(output_final)\n",
    "import shutil\n",
    "shutil.make_archive(\"/kaggle/working/modelo_travian_v2_completo\", 'zip', output_final)\n",
    "print(\"‚úÖ‚úÖ‚úÖ ¬°LISTO! Descarga el ZIP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52398b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T15:59:28.788551Z",
     "iopub.status.busy": "2025-12-02T15:59:28.787975Z",
     "iopub.status.idle": "2025-12-03T01:10:49.309247Z",
     "shell.execute_reply": "2025-12-03T01:10:49.308293Z",
     "shell.execute_reply.started": "2025-12-02T15:59:28.788526Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # Mantenemos esto por seguridad\n",
    "\n",
    "from transformers import GPT2LMHeadModel, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "# --- 1. LOCALIZAR MODELO (Igual que antes) ---\n",
    "nombre_carpeta_objetivo = \"Backup_Modelo_Travian_V1\"\n",
    "ruta_modelo = None\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    if nombre_carpeta_objetivo in dirs:\n",
    "        ruta_modelo = os.path.join(root, nombre_carpeta_objetivo)\n",
    "        break\n",
    "if not ruta_modelo:\n",
    "    ruta_modelo = \"/kaggle/input/proto-ascii-art-001/Backup_Modelo_Travian_V1\"\n",
    "\n",
    "print(f\"‚úÖ Modelo base: {ruta_modelo}\")\n",
    "\n",
    "# --- 2. CARGAR ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(ruta_modelo)\n",
    "model = GPT2LMHeadModel.from_pretrained(ruta_modelo)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# --- 3. CONFIGURACI√ìN REALISTA (2 √âPOCAS) ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/travian_ascii_reloaded\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=2,              # <--- CAMBIO CLAVE: Solo 2 vueltas.\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=200,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=0\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# --- 4. ENTRENAR ---\n",
    "# C√°lculo r√°pido: Si va a 0.20 it/s, esto tardar√° unas 8-9 horas.\n",
    "# Kaggle aguanta 12h. ¬°ESTAMOS DENTRO!\n",
    "print(\"üöÄ Iniciando Re-entrenamiento (Ajustado a 2 √©pocas para terminar hoy)...\")\n",
    "trainer.train()\n",
    "\n",
    "# --- 5. GUARDAR ---\n",
    "output_final = \"/kaggle/working/modelo_travian_v2_final\n",
    "\"\n",
    "trainer.save_model(output_final)\n",
    "tokenizer.save_pretrained(output_final)\n",
    "import shutil\n",
    "shutil.make_archive(\"/kaggle/working/modelo_travian_v2_completo\", 'zip', output_final)\n",
    "print(\"‚úÖ‚úÖ‚úÖ ¬°PROCESO TERMINADO! Descarga el ZIP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228acf3a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# C√ìDIGO DE EMERGENCIA: EJECUTAR SOLO SI PARAS EL ENTRENAMIENTO MANUALMENTE\n",
    "print(\"üö® GUARDADO DE EMERGENCIA üö®\")\n",
    "trainer.save_model(\"/kaggle/working/modelo_salvado_emergencia\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/modelo_salvado_emergencia\")\n",
    "\n",
    "import shutil\n",
    "shutil.make_archive(\"/kaggle/working/modelo_emergencia_zip\", 'zip', \"/kaggle/working/modelo_salvado_emergencia\")\n",
    "print(\"‚úÖ ¬°Salvado! Descarga el ZIP de emergencia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ebc110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T01:15:44.371097Z",
     "iopub.status.busy": "2025-12-03T01:15:44.370836Z",
     "iopub.status.idle": "2025-12-03T01:15:44.400685Z",
     "shell.execute_reply": "2025-12-03T01:15:44.399810Z",
     "shell.execute_reply.started": "2025-12-03T01:15:44.371079Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# 1. Cargar el modelo reci√©n horneado\n",
    "ruta_modelo = \"/kaggle/working/modelo_travian_v2_final\"\n",
    "\n",
    "print(\"üè∞ Cargando al Arquitecto Travian...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(ruta_modelo)\n",
    "model = AutoModelForCausalLM.from_pretrained(ruta_modelo)\n",
    "\n",
    "# Mover a GPU para que sea r√°pido\n",
    "model.cuda()\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# 2. Funci√≥n para imprimir bonito\n",
    "def imprimir_ascii(texto):\n",
    "    print(\"\\n\" + \"‚öîÔ∏è\" * 30)\n",
    "    print(texto.replace(\"<|startoftext|>\", \"\").replace(\"<|endoftext|>\", \"\"))\n",
    "    print(\"‚öîÔ∏è\" * 30 + \"\\n\")\n",
    "\n",
    "# 3. PROMPTS DE PRUEBA\n",
    "prompts = [\n",
    "    \"<|startoftext|>\\nUser: Dibuja un ASCII art de buildings castle\\nAI:\\n\",\n",
    "    \"<|startoftext|>\\nUser: Dibuja un ASCII art de un mapa\\nAI:\\n\",\n",
    "    \"<|startoftext|>\\nUser: Dibuja un ASCII art de animals dragons\\nAI:\\n\"\n",
    "]\n",
    "\n",
    "print(\"üé® GENERANDO ARTE (Momento de la verdad)...\\n\")\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"--- Prompt: {prompt.strip()} ---\")\n",
    "    \n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=800,   # Suficiente para un dibujo grande\n",
    "        temperature=0.6,      # Bajo para mantener las paredes rectas\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2, # IMPORTANTE: Con loss 0.6 puede querer repetir mucho, esto lo frena\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    imprimir_ascii(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62755c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T01:17:46.427234Z",
     "iopub.status.busy": "2025-12-03T01:17:46.426751Z",
     "iopub.status.idle": "2025-12-03T01:17:46.456579Z",
     "shell.execute_reply": "2025-12-03T01:17:46.455661Z",
     "shell.execute_reply.started": "2025-12-03T01:17:46.427211Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Cargamos desde la carpeta descomprimida (que aun esta ahi)\n",
    "ruta = \"/kaggle/working/modelo_travian_v2_final\"\n",
    "\n",
    "print(\"üè∞ Cargando Arquitecto Travian V2...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(ruta)\n",
    "model = AutoModelForCausalLM.from_pretrained(ruta).cuda()\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# Prompt de prueba\n",
    "prompt = \"<|startoftext|>\\nUser: Dibuja un ASCII art de buildings castle\\nAI:\\n\"\n",
    "\n",
    "print(\"üé® Generando Castillo...\")\n",
    "output = generator(\n",
    "    prompt,\n",
    "    max_new_tokens=600,\n",
    "    temperature=0.65,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.2,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c537f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T01:19:41.154918Z",
     "iopub.status.busy": "2025-12-03T01:19:41.154604Z",
     "iopub.status.idle": "2025-12-03T01:20:24.206480Z",
     "shell.execute_reply": "2025-12-03T01:20:24.205637Z",
     "shell.execute_reply.started": "2025-12-03T01:19:41.154898Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INTENTO DE REANIMACI√ìN DE LIBRER√çAS\n",
    "# Solo haz esto si YA TIENES EL ZIP EN TU PC\n",
    "\n",
    "!pip install --force-reinstall transformers==4.37.2\n",
    "!pip install --force-reinstall tokenizers==0.15.2\n",
    "\n",
    "print(\"üîÑ Librer√≠as reinstaladas. Intentando importar de nuevo...\")\n",
    "\n",
    "# Probamos importar solo lo necesario (sin pipeline para evitar el error de video)\n",
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "\n",
    "try:\n",
    "    # Ruta de tu modelo\n",
    "    ruta_modelo = \"/kaggle/working/modelo_travian_v2_final\"\n",
    "    \n",
    "    print(\"üè∞ Cargando modelo a lo bruto...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ruta_modelo)\n",
    "    model = GPT2LMHeadModel.from_pretrained(ruta_modelo).cuda()\n",
    "    \n",
    "    print(\"‚úÖ ¬°LOGRADO! El modelo carg√≥.\")\n",
    "    \n",
    "    # Generaci√≥n manual (sin pipeline)\n",
    "    prompt = \"<|startoftext|>\\nUser: Dibuja un ASCII art de buildings castle\\nAI:\\n\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    print(\"üé® Pintando...\")\n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=500,\n",
    "        temperature=0.6,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Python sigue borracho: {e}\")\n",
    "    print(\"CONCLUSI√ìN: Vete a dormir con tu ZIP. Ma√±ana lo probamos en limpio.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8898711,
     "sourceId": 13960044,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8899249,
     "sourceId": 13960740,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8899416,
     "sourceId": 13960977,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 522194,
     "modelInstanceId": 507489,
     "sourceId": 670105,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-03T01:27:15.693302",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}