{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14031442,"sourceType":"datasetVersion","datasetId":8935116},{"sourceId":672867,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":509851,"modelId":524514},{"sourceId":674719,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":511445,"modelId":526119}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- CELDA 1: LIBRER√çAS Y PREPARACI√ìN DE DATOS ---\nimport os\nimport shutil\n\n# 1. Instalar librer√≠as\n!pip install -q transformers accelerate\n\n# 2. BUSCADOR ESPEC√çFICO (Ignora el modelo V6)\nprint(\"üìÇ Buscando dataset_v13_ANATOMY.txt ...\")\nfound_file = None\n\ntarget_filename = \"dataset_v13_ANATOMY.txt\" # El nombre exacto que buscamos\n\nfor root, dirs, files in os.walk(\"/kaggle/input\"):\n    for file in files:\n        # Solo nos interesa TU dataset, no los archivos del modelo V6\n        if file == target_filename:\n            found_file = os.path.join(root, file)\n            print(f\"   -> ¬°ENCONTRADO!: {found_file}\")\n            break\n    if found_file: break\n\nif found_file:\n    # 3. TRUCO ANTI-ERROR: Copiar a /kaggle/working/\n    # Esto soluciona el error \"Read-only file system\"\n    print(\"üöö Moviendo dataset a zona de escritura (/kaggle/working/)...\")\n    \n    writable_path = \"/kaggle/working/dataset_training.txt\"\n    shutil.copy(found_file, writable_path)\n    \n    dataset_path = writable_path # Usaremos esta ruta a partir de ahora\n    print(f\"‚úÖ TODO LISTO. Usaremos: {dataset_path}\")\n    \nelse:\n    print(\"\\n‚ùå ERROR: No encuentro 'dataset_v13_ANATOMY.txt'.\")\n    print(\"   Revisa que el dataset est√© subido correctamente en el panel derecho.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-06T18:44:06.019480Z","iopub.execute_input":"2025-12-06T18:44:06.019887Z","iopub.status.idle":"2025-12-06T18:45:18.150238Z","shell.execute_reply.started":"2025-12-06T18:44:06.019848Z","shell.execute_reply":"2025-12-06T18:45:18.149437Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0müìÇ Buscando dataset_v13_ANATOMY.txt ...\n   -> ¬°ENCONTRADO!: /kaggle/input/dataset-anatomy-13/dataset_v13_ANATOMY.txt\nüöö Moviendo dataset a zona de escritura (/kaggle/working/)...\n‚úÖ TODO LISTO. Usaremos: /kaggle/working/dataset_training.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# --- CELDA 2: CARGAR MODELO BASE ---\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\n\nmodel_name = \"gpt2\" # Usamos el base de OpenAI (Limpio)\n\nprint(f\"üß† Descargando {model_name}...\")\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\n\n# Fix para padding (necesario para GPT-2)\ntokenizer.pad_token = tokenizer.eos_token\nmodel.config.pad_token_id = model.config.eos_token_id\n\nprint(\"‚úÖ Modelo cargado en memoria.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T18:45:18.151834Z","iopub.execute_input":"2025-12-06T18:45:18.152165Z","iopub.status.idle":"2025-12-06T18:45:53.308165Z","shell.execute_reply.started":"2025-12-06T18:45:18.152141Z","shell.execute_reply":"2025-12-06T18:45:53.307547Z"}},"outputs":[{"name":"stderr","text":"2025-12-06 18:45:30.941349: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765046731.125897      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765046731.178552      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"üß† Descargando gpt2...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07c73c2a8d5e4547b81f66fd6726d515"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2df712b68024aaab6acba02d115eb36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76a3ad43ba4c407b8b771b098db449d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca092835f3d949d5a1badfb6fe02a3db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d64a64938dc848b295fb02292564fe52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75335c162b2643f3adf330d583595804"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38d3c1a7736f428581c54c9201304859"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Modelo cargado en memoria.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# --- CELDA 3: CIRUG√çA DE TOKENS (ANATOM√çA + MATRIX) ---\nprint(\"üíâ Preparando inyecci√≥n de vocabulario...\")\n\n# 1. Tokens de Estructura (Matrix)\nstructure_tokens = [f\"<L{i:02d}>\" for i in range(1, 100)]\nstructure_tokens += [\"[TOP]\", \"[MID]\", \"[BOT]\"]\nstructure_tokens += [f\"[S:{i:02d}]\" for i in range(65)] # Espacios hasta 64\n\n# 2. Tokens de Anatom√≠a (Master Edition)\nanatomy_tokens = [\n    \"[EYES_COMPLEX]\", \"[EYES_SIMPLE]\", \"[EARS]\", \"[MOUTH/NOSE]\", \"[ARMS/LEGS]\", \n    \"[PAWS/FEET]\", \"[SWORD_BLADE]\", \"[SWORD_GUARD]\", \"[SWORD_HANDLE]\", \n    \"[FLOWER_HEAD]\", \"[LEAVES/BUSH]\", \"[TRUNK/STEM]\", \"[MUSHROOM_CAP]\", \n    \"[STARS/SPACE]\", \"[ROCKET_BODY]\", \"[FLAMES/EXHAUST]\", \"[PLANET]\", \"[UFO_DOME]\",\n    \"[ROOF]\", \"[WALL/BRICK]\", \"[WINDOW]\", \"[TOWER_TOP]\", \"[DOOR/GATE]\",\n    \"[DRAGON_WINGS]\", \"[SCALES/SKIN]\", \"[CLAWS]\", \"[SMOKE/MAGIC]\",\n    \"[WHEEL]\", \"[WINDSHIELD]\", \"[BUMPER]\", \"[TEXTURE_SOLID]\", \"[TEXTURE_LIGHT]\", \n    \"[BORDER]\", \"[GENERIC]\", \"[WING]\", \"[SWORD_TIP]\", \"[SWORD_PART]\", \"[WHISKERS]\", \"[TAIL]\"\n]\n\n# 3. Fusi√≥n\nall_new_tokens = structure_tokens + anatomy_tokens\nnum_added = tokenizer.add_tokens(all_new_tokens)\nprint(f\"   -> Se han a√±adido {num_added} tokens nuevos al vocabulario.\")\n\n# 4. Redimensionar el modelo (Agrandar el cerebro)\nmodel.resize_token_embeddings(len(tokenizer))\n\nprint(\"‚úÖ Cirug√≠a completada con √©xito.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T18:45:53.308796Z","iopub.execute_input":"2025-12-06T18:45:53.309313Z","iopub.status.idle":"2025-12-06T18:45:54.114803Z","shell.execute_reply.started":"2025-12-06T18:45:53.309288Z","shell.execute_reply":"2025-12-06T18:45:54.114132Z"}},"outputs":[{"name":"stdout","text":"üíâ Preparando inyecci√≥n de vocabulario...\n   -> Se han a√±adido 206 tokens nuevos al vocabulario.\n","output_type":"stream"},{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Cirug√≠a completada con √©xito.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# --- CELDA 4: PROCESAR DATASET ---\nfrom transformers import TextDataset, DataCollatorForLanguageModeling\n\n# Verificamos que la variable exista (por si saltaste la celda 1)\nif 'dataset_path' not in globals():\n    dataset_path = \"/kaggle/working/dataset_training.txt\"\n\nprint(f\"üìö Leyendo dataset desde: {dataset_path}\")\n\ntry:\n    train_dataset = TextDataset(\n        tokenizer=tokenizer,\n        file_path=dataset_path,\n        block_size=256,\n        overwrite_cache=True # Forzar re-creaci√≥n de cach√© en zona segura\n    )\n    \n    data_collator = DataCollatorForLanguageModeling(\n        tokenizer=tokenizer, \n        mlm=False\n    )\n    print(\"‚úÖ Dataset tokenizado y listo para entrenar.\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error procesando dataset: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T18:45:54.116413Z","iopub.execute_input":"2025-12-06T18:45:54.116620Z","iopub.status.idle":"2025-12-06T18:46:17.972042Z","shell.execute_reply.started":"2025-12-06T18:45:54.116603Z","shell.execute_reply":"2025-12-06T18:46:17.971247Z"}},"outputs":[{"name":"stdout","text":"üìö Leyendo dataset desde: /kaggle/working/dataset_training.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Dataset tokenizado y listo para entrenar.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- CELDA 5: ENTRENAMIENTO ---\nfrom transformers import Trainer, TrainingArguments\n\n# Configuraci√≥n \"Hardcore\" para Kaggle (T4 x2)\ntraining_args = TrainingArguments(\n    output_dir=\"./v13_results\",\n    overwrite_output_dir=True,\n    num_train_epochs=5,            # 5 √âpocas (suficiente para ver si aprende)\n    per_device_train_batch_size=8, # Kaggle aguanta 8 u 16. Prueba 8 primero.\n    save_steps=2000,\n    save_total_limit=2,\n    learning_rate=5e-4,            # Velocidad alta inicial\n    prediction_loss_only=True,\n    fp16=True,                     # Usar GPU Tensor Cores (M√°s r√°pido)\n    logging_steps=100,\n    report_to=\"none\"               # Desactivar WandB para que no moleste\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n)\n\nprint(\"üöÄ INICIANDO ENTRENAMIENTO V13...\")\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T18:46:17.972921Z","iopub.execute_input":"2025-12-06T18:46:17.973219Z","iopub.status.idle":"2025-12-06T19:48:09.769747Z","shell.execute_reply.started":"2025-12-06T18:46:17.973190Z","shell.execute_reply":"2025-12-06T19:48:09.769027Z"}},"outputs":[{"name":"stdout","text":"üöÄ INICIANDO ENTRENAMIENTO V13...\n","output_type":"stream"},{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5745' max='5745' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5745/5745 1:01:46, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.238300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.919400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.873100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.837800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.809600</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.767400</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.774800</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.739800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.736200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.728700</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.727700</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.714600</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.694900</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.693500</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.675700</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.672800</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.658400</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.664500</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.673300</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.649000</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.651400</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.653300</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.633300</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.608200</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.623600</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.605600</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.604400</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.626300</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.616300</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.583100</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.601900</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.598600</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.599100</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.586700</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.586400</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.560500</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.570300</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.561900</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>0.564300</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.568100</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>0.555800</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.554800</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>0.560800</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.558800</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.551200</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>0.553900</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>0.533100</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>0.528700</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>0.512700</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.527100</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>0.524500</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>0.529900</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>0.524500</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>0.525900</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.525700</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>0.528100</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>0.521800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\nYou may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5745, training_loss=0.6372228800057327, metrics={'train_runtime': 3708.4409, 'train_samples_per_second': 24.775, 'train_steps_per_second': 1.549, 'total_flos': 1.200310272e+16, 'train_loss': 0.6372228800057327, 'epoch': 5.0})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# --- CELDA 6: GUARDAR MODELO ---\noutput_path = \"./ASCII-GPT-V13-ANATOMIST\"\n\nprint(\"üíæ Guardando modelo final...\")\ntrainer.save_model(output_path)\ntokenizer.save_pretrained(output_path)\n\nprint(f\"‚úÖ Modelo guardado en {output_path}\")\nprint(\"   (Recuerda descargar la carpeta o hacer un zip desde el panel derecho)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T19:48:09.770542Z","iopub.execute_input":"2025-12-06T19:48:09.771262Z","iopub.status.idle":"2025-12-06T19:48:10.800964Z","shell.execute_reply.started":"2025-12-06T19:48:09.771239Z","shell.execute_reply":"2025-12-06T19:48:10.800184Z"}},"outputs":[{"name":"stdout","text":"üíæ Guardando modelo final...\n‚úÖ Modelo guardado en ./ASCII-GPT-V13-ANATOMIST\n   (Recuerda descargar la carpeta o hacer un zip desde el panel derecho)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# --- CELDA DE SEGURIDAD Y DESCARGA AUTOM√ÅTICA ---\nimport shutil\nfrom IPython.display import FileLink\n\n# 1. Comprimir la carpeta del modelo\noutput_dir = \"./ASCII-GPT-V13-ANATOMIST\"\nzip_name = \"MODELO_RESCATADO_V13.zip\"\n\nprint(\"üì¶ Comprimiendo modelo para evacuaci√≥n inmediata...\")\nshutil.make_archive(zip_name.replace('.zip', ''), 'zip', output_dir)\n\nprint(\"‚úÖ Compresi√≥n lista.\")\n\n# 2. Generar Link de Descarga\nprint(f\"‚¨áÔ∏è HAZ CLIC AQU√ç ABAJO PARA DESCARGARLO YA:\")\ndisplay(FileLink(zip_name))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T19:48:10.801741Z","iopub.execute_input":"2025-12-06T19:48:10.801998Z","iopub.status.idle":"2025-12-06T19:48:34.957032Z","shell.execute_reply.started":"2025-12-06T19:48:10.801970Z","shell.execute_reply":"2025-12-06T19:48:34.956404Z"}},"outputs":[{"name":"stdout","text":"üì¶ Comprimiendo modelo para evacuaci√≥n inmediata...\n‚úÖ Compresi√≥n lista.\n‚¨áÔ∏è HAZ CLIC AQU√ç ABAJO PARA DESCARGARLO YA:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/MODELO_RESCATADO_V13.zip","text/html":"<a href='MODELO_RESCATADO_V13.zip' target='_blank'>MODELO_RESCATADO_V13.zip</a><br>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import os\nimport zipfile\n\n# 1. Configuraci√≥n de Rutas\n# Asumimos que el zip est√° en el directorio actual (si lo acabas de subir)\nzip_path = \"MODELO_RESCATADO_V13.zip\" \nextract_path_v13 = \"/kaggle/input/ascii-art-v13/pytorch/default/1\"\n\n# 2. Descomprimir V13\nif not os.path.exists(extract_path_v13):\n    print(f\"üì¶ Descomprimiendo {zip_path}...\")\n    try:\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall(extract_path_v13)\n        print(\"‚úÖ V13 Descomprimido y listo.\")\n    except FileNotFoundError:\n        print(f\"‚ùå ERROR: No encuentro '{zip_path}'. S√∫belo a Kaggle primero.\")\nelse:\n    print(\"‚ö° V13 ya estaba descomprimido.\")\n\n# 3. Instalar librer√≠as necesarias\n!pip install -q transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T20:32:59.513758Z","iopub.execute_input":"2025-12-06T20:32:59.514592Z","iopub.status.idle":"2025-12-06T20:33:03.643640Z","shell.execute_reply.started":"2025-12-06T20:32:59.514508Z","shell.execute_reply":"2025-12-06T20:33:03.642343Z"}},"outputs":[{"name":"stdout","text":"‚ö° V13 ya estaba descomprimido.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel\nimport torch\n\n# --- CARGAR V13 (EL ANATOMISTA) ---\nprint(\"üß† Cargando V13 (Anatomista)...\")\ntokenizer_v13 = GPT2Tokenizer.from_pretrained(extract_path_v13)\nmodel_v13 = GPT2LMHeadModel.from_pretrained(extract_path_v13)\nmodel_v13.eval() # Modo evaluaci√≥n\n\n# --- CARGAR V6 (EL ANTIGUO) ---\n# BUSCA LA RUTA EN TU PANEL DERECHO (INPUTS) Y P√âGALA AQU√ç\n# Deber√≠a ser algo como /kaggle/input/ascii-art-v6/...\n# Si no sabes la ruta exacta, corre os.listdir(\"/kaggle/input\") en otra celda\npath_v6 = \"/kaggle/input/ascii-art-v6/pytorch/default/1\" # <--- ¬°VERIFICA ESTO!\n\nprint(f\"üß† Cargando V6 (Old School) desde {path_v6}...\")\ntry:\n    tokenizer_v6 = GPT2Tokenizer.from_pretrained(path_v6)\n    model_v6 = GPT2LMHeadModel.from_pretrained(path_v6)\n    model_v6.eval()\n    print(\"‚úÖ Ambos modelos cargados en CPU.\")\nexcept OSError:\n    print(\"‚ùå ERROR CON V6: Revisa la ruta 'path_v6'. Copiala del panel derecho.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T20:33:19.521322Z","iopub.execute_input":"2025-12-06T20:33:19.521734Z","iopub.status.idle":"2025-12-06T20:34:09.323093Z","shell.execute_reply.started":"2025-12-06T20:33:19.521703Z","shell.execute_reply":"2025-12-06T20:34:09.321971Z"}},"outputs":[{"name":"stderr","text":"2025-12-06 20:33:39.647827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765053219.965968      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765053220.059775      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"üß† Cargando V13 (Anatomista)...\nüß† Cargando V6 (Old School) desde /kaggle/input/ascii-art-v6/pytorch/default/1...\n‚úÖ Ambos modelos cargados en CPU.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import re\n\ndef render_v13_vector(prompt_text, temp=0.4):\n    # Formato espec√≠fico del V13\n    full_prompt = f\"<|startoftext|>\\nUser: Dibuja un ASCII art de {prompt_text}\\nAI:\\n<L01>\"\n    \n    inputs = tokenizer_v13(full_prompt, return_tensors=\"pt\")\n    \n    # Generar (CPU)\n    with torch.no_grad():\n        outputs = model_v13.generate(\n            **inputs,\n            max_new_tokens=350,\n            do_sample=True,\n            temperature=temp,\n            top_k=50,\n            top_p=0.95,\n            repetition_penalty=1.15, # Evitar bucles\n            pad_token_id=tokenizer_v13.eos_token_id,\n            eos_token_id=tokenizer_v13.eos_token_id\n        )\n    \n    raw_text = tokenizer_v13.decode(outputs[0], skip_special_tokens=False)\n    \n    # Limpieza\n    if \"AI:\\n\" in raw_text:\n        content = raw_text.split(\"AI:\\n\")[1]\n    else:\n        content = raw_text\n    content = content.split(\"<|endoftext|>\")[0]\n\n    # --- MOSTRAR RAW (LO QUE PIENSA) ---\n    print(f\"\\nü§ñ V13 C√ìDIGO (RAW VECTOR):\")\n    lines = re.split(r'<L\\d+>', content)\n    for i, line in enumerate(lines[:5]): # Solo primeras 5 l√≠neas para no spamear\n        if line.strip(): print(f\"<L{i:02d}> {line.strip()}\")\n    print(\"... (resto oculto) ...\")\n\n    # --- MOSTRAR RENDER (LO QUE DIBUJA) ---\n    print(f\"\\n‚ú® V13 RENDERIZADO (LIMPIO):\")\n    final_art = []\n    for line in lines:\n        if not line.strip(): continue\n        \n        # 1. Decodificar Espacios [S:xx]\n        spaces = 0\n        match = re.search(r'\\[S:(\\d+)\\]', line)\n        if match: spaces = int(match.group(1))\n        \n        # 2. Borrar todas las etiquetas [TAG]\n        clean_line = re.sub(r'\\[.*?\\]', '', line).strip()\n        \n        # 3. Dibujar\n        if clean_line:\n            final_art.append(\" \" * spaces + clean_line)\n            \n    print(\"\\n\".join(final_art))\n    print(\"-\" * 40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T20:34:56.385626Z","iopub.execute_input":"2025-12-06T20:34:56.386098Z","iopub.status.idle":"2025-12-06T20:34:56.400031Z","shell.execute_reply.started":"2025-12-06T20:34:56.386059Z","shell.execute_reply":"2025-12-06T20:34:56.398553Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def battle_arena(prompt, temperatures=[0.2, 0.5, 0.8]):\n    print(f\"\\n{'='*60}\")\n    print(f\"ü•ä PELEA DE IA: PROMPT '{prompt}'\")\n    print(f\"{'='*60}\")\n\n    for temp in temperatures:\n        print(f\"\\nüå°Ô∏è TEMPERATURA: {temp}\")\n        print(f\"{'-'*20}\")\n        \n        # --- TURNO DE V13 (ANATOMISTA) ---\n        print(\"üü¶ MODELO V13 (Vectorial):\")\n        try:\n            render_v13_vector(prompt, temp)\n        except Exception as e:\n            print(f\"Error V13: {e}\")\n\n        # --- TURNO DE V6 (ANTIGUO) ---\n        print(\"üüß MODELO V6 (Cl√°sico):\")\n        full_prompt_v6 = f\"User: Dibuja un ASCII art de {prompt}\\nAI:\\n\"\n        inputs_v6 = tokenizer_v6(full_prompt_v6, return_tensors=\"pt\")\n        \n        with torch.no_grad():\n            out_v6 = model_v6.generate(\n                **inputs_v6,\n                max_new_tokens=300,\n                do_sample=True,\n                temperature=temp,\n                repetition_penalty=1.2,\n                pad_token_id=tokenizer_v6.eos_token_id\n            )\n        text_v6 = tokenizer_v6.decode(out_v6[0], skip_special_tokens=True)\n        # Limpiar prompt\n        clean_v6 = text_v6.replace(full_prompt_v6, \"\").split(\"<|endoftext|>\")[0]\n        print(clean_v6)\n        print(\"-\" * 40)\n\n# --- ¬°FIGHT! ---\n# Probamos las categor√≠as cr√≠ticas del dataset anat√≥mico\nbattle_arena(\"Weapons Swords\", temperatures=[0.3, 0.6])\nbattle_arena(\"Animals Cats\", temperatures=[0.5])\nbattle_arena(\"Space Aliens\", temperatures=[0.5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T20:35:00.746691Z","iopub.execute_input":"2025-12-06T20:35:00.747526Z","iopub.status.idle":"2025-12-06T20:37:24.140743Z","shell.execute_reply.started":"2025-12-06T20:35:00.747495Z","shell.execute_reply":"2025-12-06T20:37:24.139755Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nü•ä PELEA DE IA: PROMPT 'Weapons Swords'\n============================================================\n\nüå°Ô∏è TEMPERATURA: 0.3\n--------------------\nüü¶ MODELO V13 (Vectorial):\n\nü§ñ V13 C√ìDIGO (RAW VECTOR):\n<L01> [TOP]   [FLAMES/EXHAUST]   [S:05]  ,-\"\"\"\"-.\n<L02> [MID]   [TRUNK/STEM]   [S:04]  /        \\\n<L03> [MID]   [TRUNK/STEM]   [S:03]  |          |\n<L04> [BOT]   [MOUTH/NOSE]   [S:03]  \\_________/\n... (resto oculto) ...\n\n‚ú® V13 RENDERIZADO (LIMPIO):\n     ,-\"\"\"\"-.\n    /        \\\n   |          |\n   \\_________/\njgs '---------'\n     '----'\n^jgs^^^^^^^\n        '\n^jgs^^^^^^^\n         '\n          '\n           '\n           '\n^jgs^^^^^^^\n          '\n           '\n           '\n           '\n           '\n           '\n           '\n           '\n           '\n           '\n           '\n           '\n           '\n           '\n           '\n           '\n            '\n'\n'\n----------------------------------------\nüüß MODELO V6 (Cl√°sico):\n                                                                                                                                                                                                                                                                                                            \n----------------------------------------\n\nüå°Ô∏è TEMPERATURA: 0.6\n--------------------\nüü¶ MODELO V13 (Vectorial):\n\nü§ñ V13 C√ìDIGO (RAW VECTOR):\n<L01> [TOP]   [MOUTH/NOSE]   [S:00]  .____________________________________________.\n<L02> [MID]   [MOUTH/NOSE]   [S:00]  | _________________________________________  ||\n<L03> [MID]   [ARMS/LEGS]   [S:00]  |                                                         |\n<L04> [MID]   [ARMS/LEGS]   [S:00]  |                                                           |\n... (resto oculto) ...\n\n‚ú® V13 RENDERIZADO (LIMPIO):\n.____________________________________________.\n| _________________________________________  ||\n|                                                         |\n|                                                           |\n|______________________________ldb\n  ----------___________ldb\n         -----\n         (FL) by Nick 30\n            (CJ) by Nick 30\n             '----'\nafter\n               niki\n                  niki\n                  love love love love love love love love love love love love love love love love love love love love love love love love love love love love lov\nove love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love love\n----------------------------------------\nüüß MODELO V6 (Cl√°sico):\n      .--.  ,.--,  _  |\\|_/|_|\\_|_ |\\__, |_|_|\\___|;,.,---..-.  /|  ;|   \\                                              \n     (   \\`;'-'-.;,-' `'--''--'   '--'.\\_/.-'-.//,'                  `''--._.' ) //)   :\\\\                         __       \n       \\\\`._____,,----''--...______...---'`                                                                                   \n----------------------------------------\n\n============================================================\nü•ä PELEA DE IA: PROMPT 'Animals Cats'\n============================================================\n\nüå°Ô∏è TEMPERATURA: 0.5\n--------------------\nüü¶ MODELO V13 (Vectorial):\n\nü§ñ V13 C√ìDIGO (RAW VECTOR):\n<L01> [TOP]   [FLAMES/EXHAUST]   [S:11]  ,.----.\n<L02> [TOP]   [TRUNK/STEM]   [S:10]  |      \\\n<L03> [MID]   [TRUNK/STEM]   [S:10]  |       \\\n<L04> [MID]   [TRUNK/STEM]   [S:10]  |        \\\n... (resto oculto) ...\n\n‚ú® V13 RENDERIZADO (LIMPIO):\n           ,.----.\n          |      \\\n          |       \\\n          |        \\\n          |         )\n          |        (\nhjw       |_________/\n    _____|______________________________\n   (____________)\n     SSt\n      from Dustin Slater\n         Berton Corson\nmic\nmic\nmic\n mic\n  mic\n   mic\n    mic\n    mic\nmic\n    mic\n    mic\nmic\nmic\nmic\nmic\nmic\nmic\nmic\nmic\n----------------------------------------\nüüß MODELO V6 (Cl√°sico):\n                                 ._.\n  __ _   ___ _____ ____ _ __ | '_ \\ / _ \\/ __|\n | || (__\\ //\\\\   ///--\\\\  \\\\//)   /_//__\\-._\\\n | ;|| `-._\\/;`-'||                                     \n |=|___/_]______[_\\__][__]______.'  '.                    \n                                                            \n                                                       \n            \n----------------------------------------\n\n============================================================\nü•ä PELEA DE IA: PROMPT 'Space Aliens'\n============================================================\n\nüå°Ô∏è TEMPERATURA: 0.5\n--------------------\nüü¶ MODELO V13 (Vectorial):\n\nü§ñ V13 C√ìDIGO (RAW VECTOR):\n<L01> [TOP]   [FLAMES/EXHAUST]   [S:01]  _                                                                                      _\n<L02> [MID]   [MOUTH/NOSE]   [S:00]  ( `-._    __   ___     ___     ___    __   __     ___    ___    ___    ___\n<L03> [MID]   [EARS]   [S:01]  \\ /\\ \\/ /  \\__ \\  /\\ \\/ /  \\__ \\  /\\ \\/ /  \\__ \\  /\\ \\/ /  \\__ \\  /\\ \\/ /\n<L04> [MID]   [EARS]   [S:01]  /_/  \\__ \\  /___/\\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/\n... (resto oculto) ...\n\n‚ú® V13 RENDERIZADO (LIMPIO):\n _                                                                                      _\n( `-._    __   ___     ___     ___    __   __     ___    ___    ___    ___\n \\ /\\ \\/ /  \\__ \\  /\\ \\/ /  \\__ \\  /\\ \\/ /  \\__ \\  /\\ \\/ /  \\__ \\  /\\ \\/ /\n /_/  \\__ \\  /___/\\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/  \\_\\/\n  _/\n----------------------------------------\nüüß MODELO V6 (Cl√°sico):\n            .--.                                                                                                                                                                                                                                                                                              \n----------------------------------------\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport re\n\ndef probe_v13(category, specific_temps=[0.2, 0.5, 0.8]):\n    print(f\"\\n{'='*60}\")\n    print(f\"üî¨ SONDA PROFUNDA: {category.upper()}\")\n    print(f\"{'='*60}\")\n    \n    # Prompt forzado V13\n    prompt = f\"<|startoftext|>\\nUser: Dibuja un ASCII art de {category}\\nAI:\\n<L01>\"\n    inputs = tokenizer_v13(prompt, return_tensors=\"pt\")\n    \n    for temp in specific_temps:\n        print(f\"\\nüå°Ô∏è TEMPERATURA: {temp}\")\n        \n        with torch.no_grad():\n            outputs = model_v13.generate(\n                **inputs,\n                max_new_tokens=400,\n                do_sample=True,\n                temperature=temp,\n                top_k=50,\n                top_p=0.95,\n                repetition_penalty=1.12, \n                pad_token_id=tokenizer_v13.eos_token_id,\n                eos_token_id=tokenizer_v13.eos_token_id\n            )\n        \n        raw_text = tokenizer_v13.decode(outputs[0], skip_special_tokens=False)\n        \n        # Extracci√≥n\n        if \"AI:\\n\" in raw_text:\n            content = raw_text.split(\"AI:\\n\")[1]\n        else:\n            content = raw_text\n        content = content.split(\"<|endoftext|>\")[0]\n        \n        # --- AN√ÅLISIS DE ETIQUETAS (¬øQu√© est√° pensando?) ---\n        # Buscamos las etiquetas sem√°nticas que us√≥ (ej: [EYES], [ROOF])\n        tags_found = set(re.findall(r'\\[[A-Z_]+\\]', content))\n        # Filtramos las aburridas\n        tags_found = {t for t in tags_found if t not in [\"[TOP]\", \"[MID]\", \"[BOT]\"]}\n        \n        print(f\"üß† ETIQUETAS DETECTADAS: {list(tags_found)}\")\n        \n        # --- RENDERIZADO ---\n        print(\"-\" * 40)\n        lines = re.split(r'<L\\d+>', content)\n        for line in lines:\n            line = line.strip()\n            if not line: continue\n            \n            # Decodificar espacio [S:xx]\n            spaces = 0\n            match = re.search(r'\\[S:(\\d+)\\]', line)\n            if match: spaces = int(match.group(1))\n            \n            # Limpiar basura visual\n            clean = re.sub(r'\\[.*?\\]', '', line).strip()\n            \n            # Filtro anti-basura simple\n            if \"=====\" in clean or \"-----\" in clean or len(clean) > 80:\n                continue\n                \n            print(\" \" * spaces + clean)\n        print(\"-\" * 40)\n\n# --- BATER√çA DE PRUEBAS ---\n\n# 1. Castillos (Prueba de alineaci√≥n vertical y torres)\nprobe_v13(\"Buildings Castles\", specific_temps=[0.3, 0.6])\n\n# 2. Dragones (Prueba de anatom√≠a compleja: alas, garras)\nprobe_v13(\"Fantasy Dragons\", specific_temps=[0.5, 0.7])\n\n# 3. Insectos (Prueba de patas y simetr√≠a peque√±a)\nprobe_v13(\"Animals Insects\", specific_temps=[0.4])\n\n# 4. Coches (Prueba de ruedas [WHEEL])\nprobe_v13(\"Vehicles Cars\", specific_temps=[0.4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T20:48:36.320732Z","iopub.execute_input":"2025-12-06T20:48:36.321155Z","iopub.status.idle":"2025-12-06T20:50:17.904201Z","shell.execute_reply.started":"2025-12-06T20:48:36.321132Z","shell.execute_reply":"2025-12-06T20:50:17.903159Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nüî¨ SONDA PROFUNDA: BUILDINGS CASTLES\n============================================================\n\nüå°Ô∏è TEMPERATURA: 0.3\nüß† ETIQUETAS DETECTADAS: []\n----------------------------------------\n|\n----------------------------------------\n\nüå°Ô∏è TEMPERATURA: 0.6\nüß† ETIQUETAS DETECTADAS: []\n----------------------------------------\n     ______________\n    /______________\\\n   | |             | |\n   |_|___________|_|\nejm97 |_____|\n       (___)\n        -K-\n          `\nejm97      hjw\n             `\n             nn\n               nn\n              nn\n              nn\n              nn\n              nn\n                nn\n                 nn\n                  nn\n                  nn\n                   nn\n                    nn\n                      nn\n                     nn\n                      nn\n                      nn\n                      nn\n                      nn\nnn\n                      n\n                      nn\n                      nn\n                      nn\n                      nn\n                      n\n                      n\n                      nn\n----------------------------------------\n\n============================================================\nüî¨ SONDA PROFUNDA: FANTASY DRAGONS\n============================================================\n\nüå°Ô∏è TEMPERATURA: 0.5\nüß† ETIQUETAS DETECTADAS: []\n----------------------------------------\n|                                              |\n|                                                   |\n|                                                     |\n|                                                             |\n|\n----------------------------------------\n\nüå°Ô∏è TEMPERATURA: 0.7\nüß† ETIQUETAS DETECTADAS: ['[EARS]']\n----------------------------------------\n        ___\n      /   \\__\n     |___/\\___|\njgs~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\njgs^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n       ^^^^^^^^^^^^^^^^^^^^^^^^^\n           ^^^^\nTina D.Connor\n                        Sandy Morton\n                        Sandy Morton\n                      Sandy Morton\n                       Sandy Morton\n~~~~~~~~~~~~~~~~~~~~~~~~\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n~~~~~~~~\n~~~~~~~~\n~~~~~~~~\nTina L.\nTina\n                         ~~~~~~~~\n~~~~~~~~\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n~~~~~~~~~~~~~~~~~~~~~~~~\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n----------------------------------------\n\n============================================================\nüî¨ SONDA PROFUNDA: ANIMALS INSECTS\n============================================================\n\nüå°Ô∏è TEMPERATURA: 0.4\nüß† ETIQUETAS DETECTADAS: []\n----------------------------------------\n   ___\n  / _ \\\n |    |\n |    |\n |___|\n |___|\n |___| hjw\n `\"\"` mh\n   mic\n    mic\nmic\n   mic\n    mic\nmic\n   mic\n    mic\n    mic\n     mic\nmic\n     mic\n      mic\n       mic\n         mic\n           mic\n           mic\n           mic\n           mic\nmic\n            mic\nmic\n          mic\nmic\nmic\n~~~~~~~~\n~~~~~~~~~~~~~~~~~~~~\n~~~~~~~~\n~~~~~~~~\n~~~~~~~~\n~~~~~~~~\n~~~~~~~~\n~~~~~~~~\n~~~~~~~~\n~~~~~~~~\n\n----------------------------------------\n\n============================================================\nüî¨ SONDA PROFUNDA: VEHICLES CARS\n============================================================\n\nüå°Ô∏è TEMPERATURA: 0.4\nüß† ETIQUETAS DETECTADAS: []\n----------------------------------------\n    ___\n   |=|\n   |=|\n   |=|\n^jgs^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\njgs\n----------------------------------------\n","output_type":"stream"}],"execution_count":7}]}