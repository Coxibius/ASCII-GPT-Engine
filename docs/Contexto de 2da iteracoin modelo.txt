游늼 Reporte de Estado: Proyecto ASCII-GPT (Travian Edition)
Fecha: 2 de Diciembre, 2025
Plataforma Actual: Kaggle (2x T4 GPU)
Estado: 游릭 Entrenando (Fase 2 - Refinamiento)
1. Resumen Ejecutivo
Estamos desarrollando un Modelo de Lenguaje (LLM) especializado en generar arte ASCII con tem치tica de Travian/MMORPG. El proyecto utiliza un modelo GPT-2 Small pre-entrenado, sometido a un proceso de Fine-Tuning (ajuste fino).
Actualmente, hemos superado la fase inicial de aprendizaje sint치ctico ("balbuceo") y estamos ejecutando una fase de Transferencia de Aprendizaje para mejorar la coherencia geom칠trica y estructural de los dibujos.
2. La Odisea: 쮺칩mo llegamos aqu칤?
游늴 Fase 0: Preparaci칩n de Datos
Logro: Limpieza exitosa de un dataset ruidoso.
Resultado: dataset_TRAVIAN_CLEAN_V2.txt. 100k+ ejemplos filtrados por densidad y longitud.
Hito: Se elimin칩 el "ruido" visual para que el modelo no aprendiera basura.
游빍 Fase 1: El Primer Entrenamiento (Google Colab)
Configuraci칩n: 1 칄poca, max_length=1024.
Resultado: Training Loss baj칩 de 1.35 a ~1.20.
Estado del Modelo: El modelo aprendi칩 los caracteres correctos (/, \, |, _) y la sintaxis b치sica, pero carec칤a de "memoria espacial". Los edificios sal칤an torcidos o con bucles infinitos.
Incidente: Al intentar escalar el entrenamiento, Google Colab limit칩 el uso de GPU.
Acci칩n Cr칤tica: Se realiz칩 un backup de emergencia en Google Drive (Backup_Modelo_Travian_V1).
游댃 Fase 2: Migraci칩n y Recuperaci칩n (Kaggle)
Desaf칤o: Mover el entorno a Kaggle para aprovechar las 12 horas de sesi칩n continua.
Obst치culos Superados:
Diferencias en sistemas de archivos (/content/drive vs /kaggle/input).
Errores de dependencias (pip install con internet apagado).
Crisis del Backup: Kaggle no encontraba el config.json debido a una estructura de carpetas anidadas ("Efecto Matrioska"). Se solucion칩 con un script de b칰squeda recursiva.
Cuello de Botella: La carga de datos con num_workers=2 causaba deadlocks. Se optimiz칩 a num_workers=0.
3. Entrenamiento en Curso: Especificaciones T칠cnicas
Lo que se est치 ejecutando ahora mismo en la consola no es un entrenamiento desde cero, es un Refinamiento (Fine-Tuning v2) sobre el modelo rescatado de la Fase 1.
Par치metro	Valor	Justificaci칩n
Modelo Base	Backup_Modelo_Travian_V1	Aprovechamos lo aprendido ayer (3.5 horas de c칩mputo).
칄pocas	2	Ajustado por limitaciones de tiempo (Kaggle 12h).
Context Window	1024 tokens	Necesario para dibujos grandes (castillos, mapas).
Precision	fp16 (Mixed Precision)	Acelera el c치lculo en las T4 GPUs.
Learning Rate	3e-5	Bajo para refinar detalles sin "romper" el conocimiento previo.
Batch Size	4 (Acumulaci칩n x4 = 16)	Optimizado para no desbordar la VRAM.
Velocidad	~0.18 - 0.20 it/s	Lento debido a la complejidad cuadr치tica de la atenci칩n en secuencias largas.
Tiempo Estimado	~9 Horas	Finalizar치 dentro de la ventana de sesi칩n segura.
4. 쯈u칠 esperamos obtener? (Expectativas)
Al finalizar estas 9 horas de entrenamiento, esperamos evolucionar de un "Balbuceador ASCII" a un "Arquitecto Novato".
A. Mejoras Estructurales
El objetivo principal de estas 2 칠pocas adicionales es mejorar las Long-Range Dependencies (Dependencias de largo alcance).
Antes: El modelo olvidaba d칩nde empezaba una pared hace 3 l칤neas, resultando en edificios torcidos.
Esperado: El modelo deber칤a alinear mejor las paredes verticales (|) y cerrar los techos (/ y \) con mayor precisi칩n.
B. Comportamiento del Loss
No esperamos que el Loss baje dr치sticamente (ej. a 0.5).
Esperamos una estabilizaci칩n alrededor de 1.0 - 1.1.
Nota: En ASCII art, un Loss muy bajo puede significar que el modelo est치 memorizando espacios en blanco. Un Loss estable indica que est치 aprendiendo la estructura visual.
C. Inferencia
Una vez termine, el modelo ser치 capaz de responder a prompts complejos como:
"Dibuja un ASCII art de buildings castle"
"Dibuja un ASCII art de un mapa"
Generando estructuras reconocibles, aunque probablemente a칰n requiera jugar con la temperature (0.6 - 0.7) para obtener los mejores resultados.
5. Pr칩ximos Pasos (Post-Entrenamiento)
Descarga Cr칤tica: Descargar el archivo modelo_travian_v2_completo.zip inmediatamente al terminar.
Pruebas de Inferencia: Ejecutar el script de generaci칩n ajustando repetition_penalty para evitar bucles.
Deploy (Futuro): Si el modelo es bueno, el siguiente paso ser칤a subirlo al Hugging Face Hub para usarlo desde cualquier lugar sin gastar GPU propia.
Estado Final: 游 Cruzando los dedos para que la sesi칩n de Kaggle no se desconecte en las pr칩ximas 9 horas. 춰El c칩digo est치 s칩lido!